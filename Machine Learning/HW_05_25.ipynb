{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lqER1UWidRTD",
        "outputId": "57bc772e-24e4-4a29-c68a-78d553109f2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nkmeans = KMeans(n_clusters=2, random_state=42)\\nkmeans.fit(data)\\n\\n\\nlabels = kmeans.labels_\\ncentroids = kmeans.cluster_centers_\\n\\n\\nprint(\"Cluster Labels:\", labels)\\nprint(\"Centroids:\")\\nfor i, centroid in enumerate(centroids):\\n    print(\"Cluster {}: {}\".format(i+1, centroid))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('heart_disease.csv')\n",
        "label = data.values[:, 0]\n",
        "data = np.array(data.values[:, 1:])\n",
        "\n",
        "\n",
        "'''\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans.fit(data)\n",
        "\n",
        "\n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "\n",
        "print(\"Cluster Labels:\", labels)\n",
        "print(\"Centroids:\")\n",
        "for i, centroid in enumerate(centroids):\n",
        "    print(\"Cluster {}: {}\".format(i+1, centroid))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "class KMeans:\n",
        "    def __init__(self, n_clusters=8, max_iters=100):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iters = max_iters\n",
        "\n",
        "    def fit(self, data):\n",
        "        n_samples, n_features = data.shape\n",
        "\n",
        "        \n",
        "        np.random.seed(42)\n",
        "        self.centroids = data[np.random.choice(n_samples, self.n_clusters, replace=False)]\n",
        "\n",
        "        for _ in range(self.max_iters):\n",
        "        \n",
        "            distances = cdist(data, self.centroids)\n",
        "            labels = np.argmin(distances, axis=1)\n",
        "\n",
        "        \n",
        "            new_centroids = np.zeros_like(self.centroids)\n",
        "            for i in range(self.n_clusters):\n",
        "                cluster_points = data[labels == i]\n",
        "                if len(cluster_points) > 0:\n",
        "                    new_centroids[i] = cluster_points.mean(axis=0)\n",
        "\n",
        "        \n",
        "            if np.all(self.centroids == new_centroids):\n",
        "                break\n",
        "\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "        self.labels = labels\n",
        "\n",
        "    def predict(self, data):\n",
        "        distances = cdist(data, self.centroids)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        labels = labels.flatten()\n",
        "\n",
        "        return labels\n"
      ],
      "metadata": {
        "id": "jwZ_eJHeeamk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glCMeg9vj1E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "models = []\n",
        "distortions = []\n",
        "\n",
        "for cluster in np.arange(2,10):\n",
        "    kmeans = KMeans(n_clusters=cluster, max_iters=100)\n",
        "    kmeans.fit(data)\n",
        "    models.append(kmeans)\n",
        "\n",
        "    #This the sum as distortion:\n",
        "    distances = cdist(data, kmeans.centroids, 'sqeuclidean')\n",
        "    distortions.append(distances)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uc_XyRYEf4j_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = range(2, 11)\n",
        "\n",
        "\n",
        "plt.plot(k_values, distortions, 'bx-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Distortions')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZRzFoNl_oEuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because of dim issues I've failed to visualize, so I cant conclude, however This supposed to be the correct form of visualizing the graph from which choosing the best value with the lowest sum should be seen."
      ],
      "metadata": {
        "id": "QdCcrzWDoQRn"
      }
    }
  ]
}